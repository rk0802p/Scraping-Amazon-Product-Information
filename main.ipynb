{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This project will cover Scrapping Amazon Product(single product) Information with the help of Beautiful Soup Library of Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #This library is Used to parse webpages\n",
    "import requests #this module is used to send requets\n",
    "import csv #This will be used to save the scrapped data in csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending Get request to Amazon\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US, en;q=0.5\"\n",
    "}\n",
    "\n",
    "url = \"https://www.amazon.in/dp/B0D8123CLN?pd_rd_w=fjwxt&content-id=amzn1.sym.30d86552-b860-4e75-b390-38062fb47ed4&pf_rd_p=30d86552-b860-4e75-b390-38062fb47ed4&pf_rd_r=XF11VF7S4ZCNKF4HKYFW&pd_rd_wg=BK0X6&pd_rd_r=2f75da81-eb38-4946-af88-bb418c9150c0&th=1\"  #This is the link to the product whos data we will be scrapping\n",
    "\n",
    "response = requests.get(url, headers = headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the html content\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title: Samsung Galaxy M35 5G (Daybreak Blue,6GB RAM,128GB Storage)| Corning Gorilla Glass Victus+| AnTuTu Score 595K+ | Vapour Cooling Chamber | 6000mAh Battery | 120Hz Super AMOLED Display| Without Charger\n",
      "Price: â‚¹14,999.00\n",
      "Rating: 4.1 out of 5 stars\n"
     ]
    }
   ],
   "source": [
    "#Extracting Product Title, Price and Rating\n",
    "title = soup.find(id=\"productTitle\" ).get_text().strip()\n",
    "price = soup.find(\"span\", {\"class\": \"a-offscreen\"}).get_text().strip()\n",
    "rating = soup.find(\"span\", {\"class\": \"a-icon-alt\"}).get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data for CSV file\n",
    "data = [\n",
    "    {\n",
    "        \"Title\": title, \"Price\": price, \"Rating\" : rating\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data have been successfully saved to amazon_product_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Write data to CSV \n",
    "\n",
    "with open(\"amazon_product_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\" ) as csvfile:\n",
    "    fieldnames = [\"Title\", \"Price\", \"Rating\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "print(\"data have been successfully saved to amazon_product_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
